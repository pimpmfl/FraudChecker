{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44270e5d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Financial-Transactions\" data-toc-modified-id=\"Financial-Transactions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Financial Transactions</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Leaderboard-Predict-function\" data-toc-modified-id=\"The-Leaderboard-Predict-function-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The Leaderboard Predict function</a></span></li><li><span><a href=\"#Testing-your-Implementation\" data-toc-modified-id=\"Testing-your-Implementation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Testing your Implementation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab8fb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64f7c372b96e90860c81abab27fcaf91",
     "grade": false,
     "grade_id": "cell-e73d576a3d47c12f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Financial Transactions\n",
    "\n",
    "The ability to identify fraudulent transactions is of great interest to the payments industry. In this notebook, you will make use of the binary classifier you trained on the transcations dataset to detect fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da42cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbca8b0c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f55791312e024fe367642edd8b05b8c9",
     "grade": false,
     "grade_id": "cell-b9b680c4d8d3fe22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "path = \"/data/mlproject22\" if os.path.exists(\"/data/mlproject22\") else \".\"\n",
    "train_data = pd.read_csv(os.path.join(path, \"transactions.csv.zip\"))\n",
    "X_train = train_data.drop(columns = \"Class\")\n",
    "y_train = train_data[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61537e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcfbf4adef8ec43129f89597b7c59497",
     "grade": false,
     "grade_id": "cell-039042e3f5c8bdaa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Leaderboard Predict function\n",
    "Replace the comment and `NotImplementedError` in the `leader_board_predict_fn` with code that loads your model parameters and returns the likelyhood of fraud for each transaction (i.e. row) in the values dataframe. Note that the returned array should contain a single decision function value for each transaction, indicating whether the transaction is fraudulent (i.e. it belongs to target class $1$). The higher the decision function value, the more likely that the transaction is fraud.\n",
    "You can import the packages you require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4c7b27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "078d3e7d4d77df211c92872e8e23661b",
     "grade": false,
     "grade_id": "cell-951632347ae286bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "def leader_board_predict_fn(values):\n",
    "    \n",
    "    # Load the trained model parameters\n",
    "    rf_classifier = joblib.load(\"/home/csaz7668/random_forest_params.pkl\")\n",
    "    scaler = joblib.load(\"/home/csaz7668/random_forest_scaler.pkl\")\n",
    "\n",
    "    X = values\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    # Predict the likelihood of fraud (decision function values) for each transaction\n",
    "    decision_function_values = rf_classifier.predict_proba(X_scaled)[:, 1]  # Get the probability of the positive class\n",
    "    print(decision_function_values)\n",
    "    return decision_function_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b350d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5b91dddd2a088ce77c347337e55b7ef",
     "grade": false,
     "grade_id": "cell-feda725da2aaae3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Testing your Implementation\n",
    "Your model should return the probability or decision function value that indicates the likelyhood of fraud for each input transaction. To verify that this is the case, we run your model on a subset of the transactions dataset it was trained on. There is a hidden cell that performs the actual test on the unseen test set and computes your score for the leaderboard using the [ROC AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4bfc30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3300721a523cb82c46174de8ca5c41c",
     "grade": true,
     "grade_id": "cell-973aee3c6a885301",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Train Dataset Score: 0.9935252189198022\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Test Dataset Score: 0.9527033889667291\n"
     ]
    }
   ],
   "source": [
    "def get_score():\n",
    "    \"\"\"\n",
    "    Function to compute scores for train and test datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import pathlib\n",
    "\n",
    "    try:\n",
    "        path = \"/data/mlproject22\" if os.path.exists(\"/data/mlproject22\") else \".\"\n",
    "        test_data = pd.read_csv(os.path.join(path, \"transactions.csv.zip\"))\n",
    "        X_test = test_data.drop(columns = \"Class\")\n",
    "        y_test = test_data[\"Class\"]\n",
    "        decision_function_values = leader_board_predict_fn(X_test)\n",
    "        assert decision_function_values.shape == (X_test.shape[0],)\n",
    "        dataset_score = roc_auc_score(y_test, decision_function_values)\n",
    "        assert dataset_score >= 0.0 and dataset_score <= 1.0\n",
    "    except Exception:\n",
    "        dataset_score = float(\"nan\")\n",
    "    print(f\"Train Dataset Score: {dataset_score}\")\n",
    "\n",
    "    import os\n",
    "    import pwd\n",
    "    import time\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "    user_id = pwd.getpwuid( os.getuid() ).pw_name\n",
    "    curtime = time.time()\n",
    "    dt_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    try:\n",
    "        HIDDEN_DATASET_PATH = os.path.expanduser(\"/data/mlproject22-test-data\")\n",
    "        test_data = pd.read_csv(os.path.join(HIDDEN_DATASET_PATH,\"transactions_scoreboard.csv.zip\"))\n",
    "        X_test = test_data.drop(columns=[\"Class\"])\n",
    "        y_test = test_data[\"Class\"]\n",
    "        decision_function_values = leader_board_predict_fn(X_test)\n",
    "        hiddendataset_score = roc_auc_score(y_test, decision_function_values)\n",
    "        print(f\"Test Dataset Score: {hiddendataset_score}\")\n",
    "        score_dict = dict(\n",
    "            score_hidden=hiddendataset_score,\n",
    "            score_train=dataset_score,\n",
    "            unixtime=curtime,\n",
    "            user=user_id,\n",
    "            dt=dt_now,\n",
    "            comment=\"\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        err = str(e)\n",
    "        score_dict = dict(\n",
    "            score_hidden=float(\"nan\"),\n",
    "            score_train=dataset_score,\n",
    "            unixtime=curtime,\n",
    "            user=user_id,\n",
    "            dt=dt_now,\n",
    "            comment=err\n",
    "        )\n",
    "\n",
    "    #if list(pathlib.Path(os.getcwd()).parents)[0].name == 'source':\n",
    "    #    print(\"we are in the source directory... replacing values.\")\n",
    "    #    print(pd.DataFrame([score_dict]))\n",
    "    #    score_dict[\"score_hidden\"] = -1\n",
    "    #    score_dict[\"score_train\"] = -1\n",
    "    #    print(\"new values:\")\n",
    "    #    print(pd.DataFrame([score_dict]))\n",
    "\n",
    "    pd.DataFrame([score_dict]).to_csv(\"transactions.csv\", index=False)\n",
    "    \n",
    "get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69022aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "352px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
